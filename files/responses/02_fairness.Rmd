---
title: "Long Response 2: Statistical Definitions of Fairness"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Overview

In this assignment, you will apply what we've discussed about statistical definitions of fairness. Read [this article](https://themarkup.org/news/2021/03/02/major-universities-are-using-race-as-a-high-impact-predictor-of-student-success) and [this article](https://www.apmreports.org/episode/2019/08/06/college-data-tracking-students-graduation) detailing the use of algorithms to predict student success in higher education.

Consider an algorithm that outputs a score $S$ that measures a student's risk of not graduating on time. Inputs $X$ can include grades and other data discussed in the above articles. Suppose this score $S$ is used to make predictions about $Y$, where $Y=1$ is the student graduates on time and $Y=0$ if not. Suppose $R$ describes race. Using the definitions in Chouldechova (2017), answer the following questions.

## Instructions

1. **(2 points)** Explain, in plain language, what calibration means in this context.
2. **(2 points)** Explain, in plain language, what predictive parity means in this context.
3. **(2 points)** Explain, in plain language, what error rate balance means in this context.
4. **(3 points)** Do the algorithms described in the articles above violate any of the above definitions of fairness?
5. **(3 points)** In your opinion, which of the three defintions of fairness above would be the most important to satisfy in this context? Why?
6. **(3 points)** If such an algorithm were shown to satisfy your preferred definition of fairness, would you be comfortable with its use in this context? What other ethical concerns should we consider?